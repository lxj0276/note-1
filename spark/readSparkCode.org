[[http://blog.csdn.net/lovehuangjiaju/article/details/49227919][Spark 1.5.0 远程调试]]
* 基础
** 基本概念（Basic Concepts）

1. RDD——Resillient Distributed Dataset 弹性分布式数据集。

2. Operation——作用于RDD的各种操作分为transformation和action。

3. Job——作业，一个JOB包含多个RDD及作用于相应RDD上的各种operation。

4. Stage——一个作业分为多个阶段。

5. Partition——数据分区， 一个RDD中的数据可以分成多个不同的区。

6. DAG——Directed Acycle graph，有向无环图，反应RDD之间的依赖关系。

7. Narrow dependency——窄依赖，子RDD依赖于父RDD中固定的data partition。

8. Wide Dependency——宽依赖，子RDD对父RDD中的所有data partition都有依赖。

9. Caching Managenment——缓存管理，对RDD的中间计算结果进行缓存管理以加快整体的处理速度。

不管什么样的静态模型，其在动态运行的时候无外乎由进程，线程组成。

用Spark的术语来说，static view称为dataset view，而dynamic view称为parition view。

** 部署（Deployment view）

当有Action作用于某RDD时，该action会作为一个job被提交。

在提交的过程中，DAGScheduler模块介入运算，计算RDD之间的依赖关系。RDD之间的依赖关系就形成了DAG。

每一个JOB被分为多个stage，划分stage的一个主要依据是当前计算因子的输入是否是确定的，如果是则将其分在同一个stage，避免多个stage之间的消息传递开销。

当stage被提交之后，由taskscheduler来根据stage来计算所需要的task，并将task提交到对应的worker。

Spark支持以下几种部署模式，Standalone、Mesos和YARN。这些部署模式将作为taskscheduler的初始化入参。

* Scheduler 模块
  scheduler 模块主要分为两大部分:
  1. TaskSchedulerListener
  2. TaskScheduler
* FQA
** DAGScheduler模块介入运算，计算RDD之间的依赖关系, 如何介入 ?
