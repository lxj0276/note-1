# -*- mode: org; -*-

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>

#+HTML_HEAD: <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
#+HTML_HEAD: <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
优先级用 A, B, C, D 代替, 从 A 往后优先级依次降低.
* hive on spark(耗时的离线批量处理) :A
  1. 将执行时间较长的
 hive 运行在 spark 上,调节执行参数.
  2. 用 spark sql 改写一些 hive 语句, 查看效果.
* spark streaming :A
  1. spark streaming 做实时需求.
  2. spark streaming 做实时算法训练模型. :C
* spark 数据处理, 然后写入到 es, hbase 等,做 hdfs, hive, es, hbase 等的数据对接工具 :B
* spark 做一些特殊的数据清洗(用 hive 比较难弄的复杂的数据数据清洗) :B
当处理日志的半结构化或者非结构化数据时, 对其进行清洗和转换操作时，需要结合 SQL 查询以及复杂的过程式逻辑处理，这部分工作虽然可以由 Hive SQL 结合 Python 或 shell 脚本来完成。这种方式存在效率问题，当数据量比较大的时候，流程的运行时间较长，这些 ETL 流程通常处于比较上游的位置，会直接影响到一系列下游的完成时间以及各种重要数据报表的生成。
如果用 spark 配合 sparkSQL 会是比较好的选择.
* graphX :B
  用 graphX 做分布式图计算的需求.
* spark ml :C
  基于 spark ml 做一些模型(配合征信,金融,商服等需求)
* 基于历史数据的快速交互式查询(可用 impala 代替) :D
* Spark 适用场景：
Spark 是基于内存的迭代计算框架，适用于需要多次操作特定数据集的应用场合。需要反复操作的次数越多，所需读取的数据量越大，受益越大，数据量小但是计算密集度较大的场合，受益就相对较小。
数据量不是特别大，但是要求近实时统计分析需求
* Spark 不适用场景：
内存 hold 不住的场景，在内存不足的情况下，Spark 会下放到磁盘，会降低应有的性能
有高实时性要求的流式计算业务，例如实时性要求毫秒级
由于 RDD 设计上的只读特点，所以 Spark 对于待分析数据频繁变动的情景很难做（并不是不可以），比如题主例子里的搜索，假设你的数据集在频繁变化（不停增删改），而且又需要结果具有很强的一致性（不一致时间窗口很小），那么就不合适了。
流线长或文件流量非常大的数据集不适合。你会发现你的内存不够用，集群压力大时一旦一个 task 失败会导致他前面一条线所有的前置任务全部重跑，然后恶性循环会导致更多的 task 失败，整个 sparkapp 效率极低。就不如 MapReduce！


* 讨论
1. 数据提取,合并
   数据提取, 主题提取

   清洗, 提取, 入库
   离线

   通讯录数据


业务主题

预统计

streaming 数据丢失, 重复消费问题


spark 安全(控制资源, 文件-数据): 限定能干什么
** 立项
*** hive on spark(金融, 征信 运行时间长)
*** streaming
   1. 基于 avs 日志做用户分析(app)

   2. 探针数据
*** graghX
   1. 通讯录(讨论一个项目)



app url    

* plan
** spark 安装
   1. 集群集成在 cloudera, 还是重新搭建一个?
      直接在 cloudera 中, 用 cloudera 管理 Hadoop, spark, 统一性强, 可以用界面维护, 运维应该要简单一些.
   2. 修改配置

   

** 集群安全:




** hive on spark(金融, 征信 运行时间长)
** streaming
 1. 基于 avs 日志做用户分析(app)

 2. 探针数据
** graghX
 1. 通讯录(讨论一个项目)

#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="http://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
#+HTML_HEAD: <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
#+HTML_HEAD: <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
#+HTML_HEAD: <script type="text/javascript" src="http://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>

* spark 安装及测试
** 集群安装
  1. 确定集群是集成在 cloudera, 还是重新搭建一个(不集成在 cloudera 中)?
    直接在 cloudera 中, 用 cloudera 管理 Hadoop, spark, 统一性强, 可以用界面维护, 运维应该要简单一些.
  2. 确定 spark 安装的节点(这些节点不跑 MR, 只跑 spark)
  3. 安装 spark
** 修改部分配置(做一些优化, 比如适应 hive on spark 等)
** 集群测试
  1. 在 spark 安装完时测试集群
  2. 边修改部分配置, 边测试集群

* 集群安全及测试
  [[http://www.datastart.cn/tech/2016/05/10/spark-7-security.html][Hive 的授权]]
  [[http://www.zhangrenhua.com/2016/01/31/hadoop-Hive%25E8%25BF%259B%25E9%2598%25B6-%25E8%2587%25AA%25E5%25AE%259A%25E4%25B9%2589%25E7%2594%25A8%25E6%2588%25B7%25E6%259D%2583%25E9%2599%2590%25E6%258E%25A7%25E5%2588%25B6/][Hive 进阶-自定义用户权限控制]]

** 不让没有权限的访问 spark-submit 命令
   权限没有控制, 理论上用户都可以调用 spark-submit, spark-shell, hadoop 等命令
** spark 访问 hive 表的权限
   root 用户可以读写(tmp), wangmin 用户可以读写(tmp)

   目前 hive 中(root, wangwin)对数据库表的权限是什么样的?
** hdfs 文件权限的管理(修改 hdfs 文件权限会不会对当前的 MR 有影响)
   目前 hive 仓库下 hdfs 上的文件基本上所有的表对所有用户都有读写权限
** 集群资源的可分配性(待查询可否控制)

* hive on spark
  1. 调度系统上线后, 查看计算脚本的运行时长
  2. 根据运行时长及重要程序排序, 排除优先级
  3. 先拿出几个脚本测试
     1). 直接在 spark 上跑, 测试效果
     2). 设置运行前参数, 调优, 测试效果  
  4. 根据优先级逐步上线脚本在 spark 上跑

* streaming
** 基于 avs 日志做用户分析(app)
  1. 跟数据提供方对接, 确定日志所在服务器, 位置, 日志格式等
  2. 确定技术方案(flume + kafka + streaming => (hive/hbase/hdfs ?)
  3. 实施实时流各组件的对接
  4. 开发程序解析, 分析日志信息
  5. 根据日志包含的数据分析可能的需求
  6. 根据分析得到的需求, 开发并测试程序
** 探针数据(待定)
  
* graghX
** 通讯录(讨论一个项目)
  1. 跟数据提供方对接, 确定在 oracle/mongodb/file(文件)中, 或者在其他的地方, 确定数据格式
  2. 根据第一条, 确定技术方案
  3. 实施技术方案
  4. 根据数据分析可能的需求
  5. 根据需求, 开发并测试程序
