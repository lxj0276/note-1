查看技术的浏览器兼容性: http://caniuse.com/
* Full screen api
The fullscreen API provides an easy way for web content to be presented using the user's entire screen.
HTML5中的一个api,用于element或者document的全屏
* css3 filter
Filters主要是运用在图片上，以实现一些特效。（尽管他们也能运用于video上），不过我们在些只来讨论图片上的运用。

目前支持这个属性的浏览器少得可怜，现在只是webkit支持，而且只有webkit nightly版本和Chrome 18.0.976以上以上版本才支持，所以说，你要是想看到效果就需要下载这两
个版本中的一个，我使用的是Google Chrome Canary。

语法:
elm {
filter: none | <filter-function > [ <filter-function> ]*
}

其默认值是none，他不具备继承性，其中filter-function一个具有以下值可选：

grayscale灰度
sepia褐色（求专业指点翻译）
saturate饱和度
hue-rotate色相旋转
invert反色
opacity透明度
brightness亮度
contrast对比度
blur模糊
drop-shadow阴影

* Web Audio API
Web Audio还是一个比较新的JavaScript API，它和HTML5中的&lt;audio&gt;是不同的，简单来说，&lt;audio&gt;标签是为了能在网页中嵌入音频文件，和播放器一样，具有操作界面，而Web Audio则是给了开发者对音频数据进行处理、分析的能力，例如混音、过滤等，类似于对音频数据进行PS。

一般的网站应用应该是用不倒这些API中的，但是一些游戏引擎或者在线音乐编辑等类型的网站应该用得到。

Web Audio API紧紧围绕着一个概念设计：audio context，它就像是一个有向图，途中的每个节点都是一个audio node，音频数据从源节点按照程序中指定的边一步一步的走的目的节点。
如果你接触过directshow开发，audio context就像filter manager，而audio node则是各种filter，当然，如果你是个linux开发者，这有看起来像是pipe。一个audio context中的audio node可以有很多，上面的是最简单的形式了。而audio node又包括四种，
1. 源节点（source node）
2. 处理节点（gain node、panner node、wave shaper node、oscillator node、delay node、convolver node等）
4. 目的节点（destination node）
* dom mutation observe
Mutation Observer（变动观察器）是监视DOM变动的接口。当DOM对象树发生任何变动时，Mutation Observer会得到通知。

要概念上，它很接近事件。可以理解为，当DOM发生变动会触发Mutation Observer事件。但是，它与事件有一个本质不同：事件是同步触发，也就是说DOM发生变动立刻会触发相应的事件；Mutation Observer则是异步触发，DOM发生变动以后，并不会马上触发，而是要等到当前所有DOM操作都结束后才触发。

这样设计是为了应付DOM变动频繁的情况。举例来说，如果在文档中连续插入1000个段落（p元素），会连续触发1000个插入事件，执行每个事件的回调函数，这很可能造成浏览器的卡顿；而Mutation Observer完全不同，只在1000个段落都插入结束后才会触发，而且只触发一次。

Mutation Observer有以下特点：

它等待所有脚本任务完成后，才会运行，即采用异步方式
它把DOM变动记录封装成一个数组进行处理，而不是一条条地个别处理DOM变动。
它即可以观察发生在DOM节点的所有变动，也可以观察某一类变动
目前，Firefox(14+)、Chrome(26+)、Opera(15+)、IE(11+)和Safari(6.1+)支持这个API。Safari 6.0和Chrome 18-25使用这个API的时候，需要加上WebKit前缀（WebKitMutationObserver）。可以使用下面的表达式检查浏览器是否支持这个API。

var MutationObserver = window.MutationObserver ||
    window.WebKitMutationObserver ||
    window.MozMutationObserver;

var mutationObserverSupport = !!MutationObserver;
* webRTC
WebRTC，名称源自网页实时通信（Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的技术，是谷歌2010年以6820万美元收购Global IP Solutions公司而获得的一项技术。
1.     WebRTC学习
1.1   WebRTC现状
本人最早接触WebRTC是在2011年底，那时Google已经在Android源码中加入了webrtc源码，放在/external/webrtc/，但是Android并没有用到它，更没有被浏览器使用。当时试图在Android 2.3（Gingerbread）高通平台的手机上用H.264 硬件codec替换掉WebRTC缺省使用的VP8软codec，费了不少劲勉强换掉后效果很差只得放弃。

最近得知Google最新版的Chrome for Android已经支持WebRTC，应老板的要求搭一个手机浏览器上视频通信的demo，为此在网上搜集各种资料，发现经过一年多的发展，国内外研究和使用WebRTC的人明显多起来，可用的demo也很多。在此做一个笔记，留作日后参考。

目前基于WebRTC的开发其实有两个方向，一个是基于浏览器的WebRTC应用开发，编程语言主要是JavaScript、HTML等，这也是WebRTC作为HTML5标准的组成部分原本的目的；另一个是C层面的移植和开发，作为一款非常强大的开源软件，很多领域的软件项目都可以利用到WebRTC的音视频通信和处理能力，这些场合的应用程序可能是C语言写的，也不一定与浏览器有关。本文是属于前一种方向。

1.2   WebRTC基本概念学习
WebRTC的官方资料可以从其官网http://www.webrtc.org/和W 3C网站http://www.w3.org/TR/webrtc/上看到。

学习WebRTC基础知识比较好的网站是《Getting Started with WebRTC》，网址是http://www.html5rocks.com/en/tutorials/webrtc/basics/，这个也是官网上推荐的。

对浏览器来说，WebRTC其实就是提供了3个API：

MediaStream (即getUserMedia)，用于获取媒体数据，例如来自摄像头和麦克风的视频流和音频流；

RTCPeerConnection，用于peer跟peer之间呼叫和建立连接以便传输音视频数据流；

RTCDataChannel，用于peer跟peer之间传输音视频之外的一般数据。

需要注意的是这几个API的名称在不同浏览器及同一浏览器的不同版本之间略有差异，比如PeerConnection在FireFox上叫做mozRTCPeerConnection，而在当前版本的Chrome上叫做webkitRTCPeerConnection，将来WebRTC标准化完成后会把这些前缀去掉使用统一的名称。

目前网上找到的WebRTC demo都只用到了getUserMedia和RTCPeerConnection这两个API，另一个API即RTCDataChannel似乎目前还不太成熟。

WebRTC是实现peer to peer的实时通信（可以两个或多个peer之间），在能够通信前peer跟peer之间必须建立连接，这是RTCPeerConnection的任务，为此需要借助一个信令服务器（signaling server）来进行，信令包括3种类型的信息：

Session control messages: 初始化和关闭通信，及报告错误；

Network configuration: 双方的IP地址和端口号（局域网内部IP地址需转换为外部的IP地址）；

Media capabilities: 双方的浏览器支持使用何种codecs以及多高的视频分辨率。

WebRTC并未规定使用何种信令机制和消息协议，象SIP、XMPP、XHR、WebSocket这些技术都可以用作WebRTC的信令通信。

除了信令服务器，peer跟peer建立连接还需要借助另一种服务器（称为STUN server）实现NAT/Firewall穿越，因为很多peer是处于私有局域网中，使用私有IP地址，必须转换为公有IP地址才能相互之间传输数据。这其中涉及到一些专业术语包括STUN、TURN、ICE等，具体的本人还有待学习。网上找到的WebRTC demo好象都用的是Google提供的STUN server。

peer跟peer之间一旦建立连接就可以直接传输音视频数据流，并不需要借助第三方服务器中转。

2.     WebRTC封装库
WebRTC的目的是为了简化基于浏览器的实时数据通信的开发工作量，但实际应用编程还是有点复杂，尤其调用RTCPeerConnection必须对如何建立连接、交换信令的流程和细节有较深入的理解。因此有高人为我们开发了WebRTC封装库，将WebRTC的调用细节封装起来，包装成更简单的API，使开发应用程序更简单。封装库的另一个目的是为了屏蔽不同浏览器之间的差异，例如上面说的API名称的差异。当然，这些库都是开源的，可以根据自己的需要重新修改。

目前网上找到的有两种WebRTC封装库，一个是webrtc.io，网址是https://github.com/webRTC/webRTC.io，上面有详细说明和使用方法，有很多demo使用它；另一个是SimpleWebRTC，网址是https://github.com/HenrikJoreteg/SimpleWebRTC，貌似比webrtc.io用起来更简单。

3.     WebRTC demo试用
网上可以找到一堆WebRTC demo，在code.google.com上也能找到不少WebRTC应用项目的源码。有些demo是直接调用WebRTC API开发的，但大多数是调用上述两种WebRTC封装库开发的。由于WebRTC API的名称在不同浏览器及同一浏览器的不同版本之间存在差异，所以不是所有demo都能运行在所有浏览器上。

为了找到一个可在公司局域网环境中跑在手机上的WebRTC demo，本人试用了不少demo，下面选几个有代表性的介绍，其中有两个经修改后已在本人公司的局域网环境中运行成功。

先说一下本人的测试环境：手机上的浏览器是Chrome for Android 26.0.1410.49，运行在Android 4.1.2上，这个Chrome版本本身是beta版，支持WebRTC但缺省是关闭WebRTC功能的，需要在chrome://flags中使能WebRTC并重启Chrome，或者在启动Chrome时增加命令行选项--enable-webrtc。本人在PC上运行WebRTC的浏览器是Chrome 26.0.1410.43，操作系统是Windows 7。

3.1  http://www.webrtc.org/demo（https://apprtc.appspot.com/）
这是官方的demo，功能很全，可惜不知为何https://apprtc.appspot.com/这个网址已经连不上了，不过其源码还是可以下载到的，在https://code.google.com/p/webrtc-samples/。此demo没有用任何封装库。

这个demo所使用的信令机制使用了XHR和Google App Engine Channel API ，具体我不懂。

在我的公司局域网环境里无法运行该demo。

3.2   爱立信实验室开发的WebRTC demo
据说是第一个基于浏览器的WebRTC视频通信demo，爱立信为此还开发了一个浏览器用于支持WebRTC，好象也是基于WebKit的，叫做Bowser browser（当时市场上可能还没有支持WebRTC的浏览器），该项目网址是https://labs.ericsson.com/apps/bowser。这个Bowser browser好象只支持Ubuntu 11.04 and 11.10（见https://labs.ericsson.com/apis/web-real-time-communication/downloads）。

该demo的网址是http://webrtc.labs.ericsson.net:8082。

在我的公司局域网环境里无法运行该demo。

3.3   人脸检测识别
利用WebRTC的getUserMedia从摄像头获取图像进行人脸识别的demo，例如这两个：

http://neave.com/webcam/html5/face/
http://www.raymondcamden.com/demos/2012/mar/29/test1.html

这两个demo在PC和手机上的Chrome上都可运行。

3.4   http://www.simpl.info
这个demo演示HTML, CSS and JavaScript的各种feature和使用方法，包括WebRTC的3个API：getUserMedia、RTCPeerConnection、RTCDataChannel的演示，但遗憾的是RTCPeerConnection的演示只是本地camera的画面传回给本地，并没有实现真正的设备之间音视频通信。

该项目的源码在https://github.com/samdutton/simpl。

3.5   Framegrabber
这是一个基于WebRTC实现屏幕共享（screensharing）的Chrome扩展，源码在https://github.com/samdutton/rtcshare，有关介绍可参考这篇文章：http://blog.sina.com.cn/s/blog_51396f890102es7k.html。

本人没有试用过。

3.6   http://webrtc.dennis.is
这个demo是基于库webrtc.io实现的，是webrtc.io官方的demo，使用WebSocket作为信令手段。

在我的公司局域网环境里无法运行该demo；在家里无线路由器环境下可成功运行，但只能单向传输视频。

3.7   http://v.kainy.cn
国内牛人做的，相当于是汉化版的http://webrtc.dennis.is，自然也是基于webrtc.io实现的，但使用的webrtc.io版本较老，不支持新版本Chrome所使用的API名称webkitRTCPeerConnection，所以无法在新版本Chrome上运行。具体介绍在http://blog.kainy.cn/2013/01/webrtc实现的视频聊天室应用/。

3.8   http://conversat.io
这个demo是基于库SimpleWebRTC实现的，是SimpleWebRTC官方的demo，使用WebSocket作为信令手段。

在我的公司局域网环境里无法运行该demo；在家里无线路由器环境下可成功运行，且可双向传视频，支持多个peer同时视频通信。

经修改后在本人公司局域网成功运行，试过两个手机和一个笔记本电脑同时视频通信OK。修改和运行步骤：

1.     从http://www.nodejs.org/download/下载nodejs最新版并安装，我是在Windows7 64位上安装的；

2.     在命令行下依次运行如下命令（安装运行signaling server所需的模块）：

npm install express
npm install yetify
npm install getconfig
npm install node-uuid
npm install socket.io

3.     从https://github.com/andyet/signalmaster下载信令服务器源码，该信令服务器是SimpleWebRTC缺省使用的，解开该源码后运行node server.js，该服务器监听8888端口，通过WebSocket与浏览器通信。

4.     在同一台PC上运行apache server，将从http://conversat.io网站扒下来的文件放到该server上（可在Chrome浏览器中打开http://conversat.io然后鼠标右键单击在菜单中选“另存为”、“网页，全部”即可），修改其中的 index.html 和 simplewebrtc.js，将其中 url 改为'http://10.100.156.83:8888'（其中IP地址是我的PC在公司局域网中的IP地址）。

5.     在同一局域网中的其他设备上打开Chrome浏览器，地址栏输入http://10.100.156.83，输入相同的room名称（随便起）即可开始多方视频通信，也可修改上述index.html中的“var room”一行，设定为固定的room名称，就不需要每次在每个设备上手工输入room名称了。

3.9   国内牛人开发的视频聊天室应用
这个demo是国内牛人赵书剑开发的视频聊天室，基于webrtc.io实现。

该项目源码和文档下载地址是http://ishare.iask.sina.com.cn/f/35083616.html，源码在https://github.com/zsj2145676。

经修改后在本人公司局域网成功运行，试过两个手机和一个笔记本电脑同时视频通信OK。修改和运行步骤：

1.     从http://ishare.iask.sina.com.cn/f/35083616.html下载webrtc.chatdemo.zip，解压缩，修改其中public\javascripts\client.js中的rtc.connect一行，将实际的服务器地址写进去，例如改为：rtc.connect("ws://10.100.156.83:8001", room);

2.     同上文3.8节步骤1、2安装nodejs

3.     运行node app.js，注意该demo本身已包含http server，不需要其他的比如apache server

4.     在同一局域网中的其他设备上打开Chrome浏览器，地址栏输入http://10.100.156.83:8000，输入相同的room名称（随便起）即可开始多方视频通信。
* requestAnimationFrame
HTML5/CSS3时代，我们要在web里做动画选择其实已经很多了:

你可以用CSS3的animattion+keyframes;

你也可以用css3的transition;

你还可以用通过在canvas上作图来实现动画，也可以借助jQuery动画相关的API方便地实现;

当然最原始的你还可以使用window.setTimout()或者window.setInterval()通过不断更新元素的状态位置等来实现动画，前提是画面的更新频率要达到每秒60次才能让肉眼看到流畅的动画效果。

现在又多了一种实现动画的方案，那就是还在草案当中的window.requestAnimationFrame()方法。

window.requestAnimationFrame() 将告知浏览器你马上要开始动画效果了，后者需要在下次动画前调用相应方法来更新画面。这个方法就是传递给window.requestAnimationFrame()的回调函数。

也可这个方法原理其实也就跟setTimeout/setInterval差不多，通过递归调用同一方法来不断更新画面以达到动起来的效果，但它优于setTimeout/setInterval的地方在于它是由浏览器专门为动画提供的API，在运行时浏览器会自动优化方法的调用，并且如果页面不是激活状态下的话，动画会自动暂停，有效节省了CPU开销。
[[http://www.zhangxinxu.com/wordpress/2013/09/css3-animation-requestanimationframe-tween-%E5%8A%A8%E7%94%BB%E7%AE%97%E6%B3%95/ ][CSS3动画那么强，requestAnimationFrame还有毛线用? ]]
* webGL
WebGL (Web Graphics Library) is a JavaScript API for rendering interactive 3D computer graphics and 2D graphics within any compatible web browser without the use of plug-ins.WebGL is integrated completely into all the web standards of the browser allowing GPU accelerated usage of physics and image processing and effects as part of the web page canvas. WebGL elements can be mixed with other HTML elements and composited with other parts of the page or page background.[3] WebGL programs consist of control code written in JavaScript and shader code that is executed on a computer's Graphics Processing Unit (GPU). WebGL is designed and maintained by the non-profit Khronos Group
2012年4月，Google搜索悄然上线了一个新的功能，那就是在搜索框里输入一个曲线方程，那么Google就会在搜索页里为你画出这个曲线！这也是WebGL第一次被应用在Google的搜索引擎中，使用者可以在搜索框里输入任意一个二元方程，Google都会将此方程绘制出来，并且是显示在全3D的空间中，另外还可以自由调整和编辑曲线以及方程。
如果想要临时查看一个方程的曲线，而周围又没有专业软件的时候，你可以应急使用一下Google的这个贴心新功能！不过要注意的是，这个功能只能运行在支持WebGL浏览器中，例如Chrome和Firefox，而不是IE！
* File System API
新的HTML5标准给我们带来了大量的新特性和惊喜，例如，画图的 画布Canvas，多媒体的audio和 video等等。除了上面我们提到的，还有比较新的特性 - File System API，它能够帮助我们来突破沙箱访问我们本地的文件系统，从而有效的弥补桌面和web应用之间的鸿沟。

API介绍:
HTML5 FileSystem API包括几个部分：
1.文件读取接口: File/Blob, FileList, FileReader
2.创建和写入接口: BlobBuilder, FileWriter
3.目录和文件读取接口: DirectoryReader, FileEntry/DirectoryEntry, LocalFileSystem
W3C规范定义了两种方式异步和同步(asynchronous and synchronous)。异步方式适用于普通程序，可以防止阻塞。同步方式用于Web Workers。

安全限制:
考虑到安全性，API接口设计时做了一些限制。
1.存储配额限制(quota limitations)
2.同源限制,如只能读写同域内的cookie和localStorage
3.文件类型限制，限制可执行文件的创建或者重命名为可执行文件
[[http://mao.li/javascript/html5-filesystem-api/][HTML5 FileSystem API 介绍]]
[[http://blog.csdn.net/salonzhou/article/details/28275713][HTML5之本地文件系统API - File System API]]
* Content Security Policy
内容安全策略的机制,Web应用可以使用它缓解普遍的内容注入漏洞,如跨站漏洞(XSS),内容安全策略是一个公开的策略,Web应用的作者(或服务器管理员)可以使用它限制资源的加载

例如,为了缓解XSS攻击,一个Web应用程序可以限制本身加载脚本只能从信任的URI,使攻击者难以注入恶意脚本.

内容安全策略(CSP)并不是作为内容注入漏洞的第一道防线.相反,CSP是最适合用来作为深度防御,以减少内容注入攻击所造成的危害.

通常,将现有Web应用程序应用CSP,为了获得最好的效果,作者将需要移动所有内嵌脚本和样式行,例如到外部脚本,因为用户代理不能确定是否有内嵌脚本注入攻击.

使用CSP时,Web应用可以通过提供一个Content-Security-Policy HTTP头或一个META的HTML元素.不过这样的政策只在当前文档适用而已.可以为整个网站,服务器提供应一个策略随着每个资源进行表示.
[[http://www.2cto.com/Article/201307/230739.html][Content Security Policy介绍]]
[[http://www.zhihu.com/question/21979782][知乎:Content Security Policy (CSP) 是什么？为什么它能抵御 XSS 攻击？]]
** 跨站漏洞(XSS)
业界对跨站攻击的定义如下：“跨站攻击是指入侵者在远程WEB页面的HTML代码中插入具有恶意目的的数据，用户认为该页面是可信赖的，但是当浏览器下载该页面，嵌入其中的脚本将被解释执行。”由于HTML语言允许使用脚本进行简单交互，入侵者便通过技术手段在某个页面里插入一个恶意HTML代码，例如记录论坛保存的用户信息（Cookie），由于Cookie保存了完整的用户名和密码资料，用户就会遭受安全损失。如这句简单的Javascript脚本就能轻易获取用户信息：alert(document.cookie)，它会弹出一个包含用户信息的消息框。入侵者运用脚本就能把用户信息发送到他们自己的记录页面中，稍做分析便获取了用户的敏感信息。
跨站脚本攻击分类

1、持久型XSS，又称存储型XSS 。
2、非持久型XSS，又称反射型XSS。
3、DOM-XSS，DOM（文档对象模型）。
持久型的XSS较第二、第三种XSS攻击的危害较大。
两种方式

其一由于HTML语言允许使用脚本进行简单交互，入侵者便通过技术手段在某个页面里插入一个恶意HTML代码——例如记录论坛保存的用户信息（Cookie），由 于Cookie保存了完整的用户名和密码资料，用户就会遭受安全损失。
其二XST攻击描述：攻击者将恶意代码嵌入一台已经被控制的主机上的web文件，当访问者浏览时恶意代码在浏览器中执行，然后访问者的cookie、http基本验证以及ntlm验证信息将被发送到已经被控制的主机，同时传送Trace请求给目标主机，导致cookie欺骗或者是中间人攻击。
攻击条件

XST：
1、需要目标web服务器允许Trace参数；
2、需要一个用来插入XST代码的地方；
3、目标站点存在跨域漏洞。
* Touch Events
[[http://mobiforge.com/design-development/html5-mobile-web-touch-events][HTML5 for the Mobile Web: Touch Events]]
[[https://developer.mozilla.org/en-US/docs/Web/API/Touch_events][Touch events]]
[[http://www.w3.org/TR/touch-events/][W3C Recommendation: Touch Event]]
* Date/timeinput types
html5的几个form表单的属性
[[http://www.html5rocks.com/en/tutorials/forms/html5forms/][Making Forms Fabulous with HTML5]]
[[http://www.hongkiat.com/blog/html5-form-input-type/][A Look Into HTML5 Forms Input Types: Date, Color and Range]]
* Audio & Videoelements
下面的例子使用了两个不同的音频格式。HTML5 <audio> 元素会尝试以 mp3 或 ogg 来播放音频。如果失败，代码将回退尝试 <embed> 元素。
<audio controls height="100" width="100">
  <source src="horse.mp3" type="audio/mpeg">
  <source src="horse.ogg" type="audio/ogg">
  <embed height="50" width="100" src="horse.mp3">
</audio>
* CSS3Animation
[[http://www.zhangxinxu.com/wordpress/2010/11/css3-transitions-transforms%E5%92%8Canimation%E4%BD%BF%E7%94%A8%E7%AE%80%E4%BB%8B%E4%B8%8E%E5%BA%94%E7%94%A8%E5%B1%95%E7%A4%BA/][CSS3 Transitions, Transforms和Animation使用简介与应用展示]]
*
