* 机器学习与数据分析
  主要内容:
    1. 机器学习与本课程示例概述
    2. 机器学习的角度看数学:
      - 数学分析
        导数与梯度
        Taylor 展式的应用
      - 概率论基础
        古典概型
        频率学派与贝叶斯学派
        常见概率分布
        Sigmoid/Logistic 函数的引入
* 概率论与贝叶斯先验
  主要内容:
    1. 概率论基础
      概率与直观
      常见概率分布
      Sigmoid/Logistic 函数的引入
    2. 统计量
      期望/方差/协方差/相关系数
      独立和不相关
    3. 大数定律
    4. 中心极限定理
    5. 最大似然估计
      过拟合

  本福特定律(本福德法则, Frank Benford)，又称第一数字定律，是 指在实际生活得出的一组数据中， 以 1 为首位数字出现的概率约为总 数的三成;是直观想象 1/9 的三倍。
  - 满足本福特定律 ::  阶乘/素数数列/斐波那契数列首位  住宅地址号码  经济数据反欺诈  选举投票反欺诈

** 概率公式
   - 条件概率 :: P(A|B) = P(AB) / P(B)
   - 全概率公式 :: P(A) = ∑(i) P(A|B_i)P(B_i)
   - 贝叶斯(Bayes)公式 :: P(B_i|A) = P(A|B_i)P(B_i) / (∑(j) P(A|B_j)P(B_j))
                     P(A|B) = P(B|A)P(A) / P(B)
   给定样本 x, 计算系统的参数, 即: P(θ|x) = P(x|θ)P(θ) / P(x)
     - 先验概率 P(θ) :: 没有数据支持下, θ发生的概率
     - 后验概率 P(θ|x) :: 在数据 x 的支持下, θ 发生的概率
     - 似然函数 P(x|θ) :: 给定某参数θ 的概率分布
** 分布
   1. 0-1 分布
      | X | 1 |   0 |
      |---+---+-----|
      | p | p | 1-p |
      E(X) = P
      D(X) = pq
   2. 二项分布(Bernoulli distribution)
      1) 设随机变量 X 服从参数为 n, p 二项分布, 设 X_i 为第 i 次试验中事件 A 发生的次数, i=1, 2, ..., n, 则:
        X = ∑(i=1, n) X_i
         显然, X_i 相互独立均服从参数为 p 的 0-1 分布,
        所以: E(X) = np, D(X) = np(1-p)
      2) X 的分布律为 P{X=k} = (n, k) p^k (1-p)^(n-k) , (k=0, 1, 2..., n), 则:
         E(X) = ∑(k=0, n) kP{X=k} = np
         D(X) = E(X^2) = [E(X)]^2 = np(1-p) 
   3. 泊松分布(Poisson distribution)
      设 X ~ π(λ), 且分布律为:
        P{X = k} = (λ^k / k!) e^(-λ) ,  k=0, 1, 2, ..., λ>0.
      则有
        E(X) = λ, D(X) = λ

      在实际事例中，当一个随机事件，以固定的平均瞬时速率λ(或称密度)随机且独立地出现时，那么这个事件在单位时间(面积或体积) 内出现的次数或个数就近似地服从泊松分布 P(λ)。
      某一服务设施在一定时间内到达的人数.
   4. 均匀分布
      设 X ~ U(a, b), 其概率密度为
        f(x) = { 1/(b-a) , a < x < b ,
               { 0       , 其他 .

         则: E(X) = 1/2(a + b), D(X) = (b-a)^2 / 12
   5. 指数分布
      设随机变量 X 服从指数分布, 其概率密度为:
        f(x) = { (1/θ) e^(-x/θ) , x > 0, θ > 0
               { 0              , x > 0, θ > 0

        则: E(X) = θ, D(X) = θ^2
   6. 正态分布 X ~ N(μ, σ^2 )
      E(X) = μ, D(X) = σ^2
   7. Beta 分布(可以理解为概率的概率)
      Γ(n) = (n-1)!

      Beta 分布的期望: E(X) = α / α + β



| 分布     | 参数              | 数学期望 | 方差        |
|---------+-------------------+----------+------------- |
| 两点分布 | 0 < p < 1         | p        | p(1-p)      |
| 二项分布 | n >= 1, 0 < p < 1 | np       | np(1-p)     |
| 泊松分布 | λ > 0             | λ        | λ           |
| 均匀分布 | a < b             | (a+b)/2  | (b-a)^2 /12 |
| 指数分布 | θ > 0             | θ        | θ^2         |
| 正态分布 | μ, σ > 0          | μ        | σ^2         |
*** TODO 指数族

    - State "TODO"       from              [2017-04-15 Sat 17:51]
** 期望, 方差
** TODO 似然估计
   - State "TODO"       from              [2017-04-16 Sun 11:47]
* 矩阵和线性代数
  1. 矩阵
    线性代数是有用的:以 SVD 为例
    矩阵的乘法/状态转移矩阵
    矩阵和向量组
  2. 特征值和特征向量
    对称阵、正交阵、正定阵
    数据白化
    正交基
    QR 分解/LFM
  3. 矩阵求导
    向量对向量求导
    标量对向量求导
    标量对矩阵求导
** SVD 奇异值分解(Singular Value Decomposition)
   svd 是一种重要的矩阵分解方法, 可以看做对称方阵在任意矩阵上的推广

   假设 A 是一个 m*n 阶实矩阵, 则存在一个分解使得:
     A_m*n = U_m*m Σ_m*n (V_n*n)^T
   通常将奇异值由大而小排列. 这样, Σ便能由 A 唯一确定了

   与特征值, 特征向量的概念相对应:
     1. Σ 对角线上的元素成为 *矩阵 A 的奇异值*
     2. U 的第 i 列称为 *A 的关于σ_i 的左奇异向量*
     3. V 的第 i 列称为 *A 的关于σ_i 的右奇异向量*
** 方阵的行列式

* FQA
  1. Hessian 矩阵
  2. 正定, 半正定矩阵
  3. 动态规划
