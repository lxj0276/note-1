* 分类
** 机器学习基础
   监督学习一般使用两种类型的目标变量： 标称型（有限目标集中取值） 和 数值型（可以从无限的的数值集合中取值）。
   分类算法可能面临非均衡分类问题： 当训练样本中某个分类的数据多于其他分类数据时， 会产生非均衡分类。

   分类何回归属于监督学习, 因为这类算法必须知道要预测什么， 即要知道目标变量的分类信息。
   无监督学习： 数据没有类别信息， 也不会给定目标值。
   在无监督学习中， 将数据集合分成由类似的对象组成的多个类的过程称为 *聚类* ， 将寻找描述数据统计值的过程称为 *密度估计* 。
   无监督学习可以减少数据维度。

   | 监督学习   <7>                   | 无监督学习            |
   |----------------------------------+-----------------------|
   | K-近邻算法： 线性回归              | K-均值： 最大期望算法 |
   | 朴素贝叶斯算法：局部加权线性回归     | DBSCAN：Parzen窗设计 |
   | 支持向量机： Ridge回归         |                       |
   | 决策树： Lasso最小回归系数估计   |                       |

*** 如何选择合适的算法
    1. 考虑算法的目的
       如果预测目标变量的值， 可以选择监督学习； 否则， 可以选择无监督学习。
    2. 选择监督学习算法之后 --> 确定目标变量的类型
       如果目标变量是离散的， 选择分类器算法； 如果是连续型数值， 选择回归算法。
    3. 选择无监督学习算法之后 --> 确定是否需要将数据划分为离散的组
       如果要划分为离散的组是唯一的需求， 使用聚类算法； 如果还要估计数据与每个分组的相似程度, 使用密度估计算法。

    还要考虑数据的问题， 吃哦哦你个问了解数据。
    主要了解的是特征值，重点了解特征值的以下特征：
    + 离散型变量还是连续型变量
    + 特征值中是否有缺失的值， 何种原因导致的缺失
    + 数据中是否存在异常值
    + 某个特征发生的频率如何
*** 开发机器学习应用程序的步骤
    1. 收集数据
    2. 准备输入数据
    3. 分析输入数据
    4. 训练算法（无监督学习不需要训练算法）
    5. 测试算法
    6. 使用算法
**  KNN K近邻算法

**  决策树
*** 决策树的一般流程
    1. 收集数据： 可用任何方法
    2. 准备数据： 树构造算法只适用于标称型数据， 因此数值型数据必须离散化。
    3. 分析数据： 可使用任何方法，构造树完成后，应检查图形是否符合预期。
    4. 训练算法： 构造树的数据结构
    5. 测试算法： 适用经验树计算错误率
    6. 使用算法： 可适用于任何监督学习算法， 使用决策树可以更好理解数据的内在含义。
*** Questions
    1. 如果训练集中存在多个特征，第一次选择哪个特征作为划分的参考属性呢？
** 基于概率轮的分类方法： 朴素贝叶斯
   DEADLINE: <2015-12-15 Tue>
** Logistic回归
** 支持向量机
** 利用AdaBoost元算法提高分类性能


* 利用回归预测数值型数据
** 预测数值型数据：回归
** 树回归

* 无监督学习
** 利用K-均值聚类算法对未标注数据分组
** 使用Apriori算法进行关联分析
** 使用FP-Growth 算法来高效发现频繁项集

* 其他工具
** 利用PCA来简化数据
** 利用SVD 简化数据
** 大数据与MapReduce
