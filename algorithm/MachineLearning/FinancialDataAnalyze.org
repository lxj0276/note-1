* 第一讲：数据分析基本知识复习（2 课时）
 
      1.  数据分析的基本概念
           a.  目的
           b.  数据获取和清理
           c.  数据的描述性统计
      2.  数据可视化
      3.  数据分析的常用模型
           a.  监督式模型：（广义）线性回归，决策树，随机森林，支持向量机，神经网络
           b.  非监督式模型：聚类分析，因子分析，主成分分析
           c.  半监督式模型
      4.  数据分析的常用工具
           a.  R 和 Python
 
* 第二课：银行内客户流失预警模型的介绍（2 课时）
 
** 银行客群和产品的类别
   - 银行的个人客户 :: 银行对个人客户的业务主要是以 *合理安排客户的个人财物为手段* ，为之提供存取款、小额贷款、代理投资理财、信息咨询及其他各类中介服务，由此为客户取得收益并帮助其防范风险，同时提高银行自身效益。
   - 银行的公司客户 :: 公司客户主要指与银行发生业务关系的各企事业单位及政府机关，其中以企业单位为主体。公司客户能为银行带来大量存款、贷款和收费业务，并成为银行利润的重要来源
                
   - 银行信贷类资产
     - 信用贷款
     - 抵押贷款
     - 保证书担保贷款
     - 贷款证券化
   - 银行负债业务
     - 活期存款
     - 定期存款
     - 储蓄存款
     - 可转让定期存单
     - 其他种类
** 为什么要做客户流失预警模型
   1. 客户流失的主要原因:
      - 价格流失
      - 产品流失
      - 服务流失
      - 时长流失
      - 促销流失
      - 技术流失
      - 政治流失
   2. 维护客户关系的基本方法
      - 追踪制度:
      - 产品跟进
      - 扩大销售
      - 维护访问
      - 机制维护
   3. 建立量化模型，合理预测客群的潜在流失风险
      - 常用的风险因子
      - 客户持有的产品数量、种类
      - 客户的年龄、性别
      - 受地理区域的影响
      - 受产品类别的影响
      - 交易的间隔时间
      - 营销、促销手段
      - 银行的服务方式和态度      
** 数据介绍和描述
   本案例搜集了 17,241 例数据，其中有 1,741 例流失样本，总流失率达到 10.10%
       银行自有字段 •账户类信息 •个人类信息 •存款类信息 •消费、交易类信息 •理财、基金类信息 •柜台服务、网银类信息
       外部三方数据 •外呼客服数据 •资产类数据 •其他消费类数据

   单因子分析之连续变量
       卡方检验

   多因子分析
       共线性变量的处理

* 第三课：金融客户流失预警模型中的数据预处理和特征衍生（2 课时）
** 流失数据中的极端值的处理
   - 人为降低极端值到某个正常的值
      例如用 95%的分位点代替 例:因为透支的原因信用卡使用额度超过 100%，可以用 100%来代替
   - 删除极端值
      例:极个别持卡人的年龄超过 85 岁
   - 单独建模型
      例:信用卡额度特别高
** 缺失值的处理
*** 种类
    - 完全随机缺失 :: 缺失值跟其他变量无关，例如婚姻状况的缺失
    - 随机缺失 :: 缺失值依赖于其他变量，例如“配偶姓名”的缺失取决于“婚姻状况”
    - 完全非随机缺失 :: 缺失值依赖于自己，例如高收入人群不愿易提供家庭收入
*** 处理方法
    - 删除有缺失值的属性或者样本(土豪行为)
    - 插补填充(常用于完全随机缺失且缺失度不高的情形中)
    - 将缺失当成一种属性值(常用于完全非随机缺失)
*** 连续变量缺失值的处理
    1. 对于完全随机缺失，当缺失率不高时，可以:
    - 用常数补缺，例如均值
      特别地，如果存在极端值，要考虑是否剔除极端值后再计算均值
    - 从非缺失值中随机抽样赋予缺失样本
    2. 对于依赖于其他某变量的随机缺失，可以在同一层内，用完全随机缺失的方法进行补缺
      例如:变量“收入”取决于“工作状态”。当“工作状态”=“有工作”时，缺失 的“收入”可以用所有“有工作”的持卡人的已知收入的均值代替
    3. 对于完全非随机缺失，可以当成一种属性，将该变量转化成类别变量
*** 类别变量缺失值的处理
    1. 当缺失率很低时
       - 最常出现的类别补缺
       - 可以从其他已知的样本中随机抽样进行补缺
    2. 当缺失率很高时
      考虑剔除该属性
    3. 当缺失率介于“很低”和“很高”时
      可以当成一种类别

** 特殊变量的处理
  常见归一化: 0-1 归一化, 标准归一化,...

*** 类别变量
    表述类目的变量，通常没有“次序”的概念，且取值范围有限, 比如: 性别，行业，信用卡种类

    类别变量不能直接放入模型时，需要编码:以数值的形式代替原有值
      - One-hot 编码
        red, blue, green
       +--------+----------+---------+
       | is_red | is_green | is_blue |
       +--------+----------+---------+
       |      1 |        0 |       0 |
       +--------+----------+---------+
       |      0 |        1 |       0 |
       +--------+----------+---------+
       |      0 |        0 |       1 |
       +--------+----------+---------+
        
      - Dummy
        red, blue, green
       +--------+----------+
       | is_red | is_green |
       +--------+----------+
       |      1 |        0 |
       +--------+----------+
       |      0 |        1 |
       +--------+----------+
       |      0 |        0 |
       +--------+----------+
      - 浓度编码
        数量/总数
      - WOE(Weight of Evidence) 编码
        woe_i = ln((P_yi )/ P_ni) = ln((yi/ys) / (ni/ns))
          其中，pyipyi 是这个组中响应客户，风险模型中，对应的是违约客户，指的是模型中预测变量取值为 1 的个体占所有样本中所有响应客户的比例，pnipni 是这个组中未响应客户占样本中所有未响应客户的比例，yiyi 是这个组中响应客户的数量，nini 是这个组中未响应客户的数量，ysys 是样本中所有响应客户的数量，nsns 是样本中所有未响应客户的数量。


      日期/时间型变量:
        可以基于某个基准日期，转化为天数
        以观察点为基准，将所有开户日期转为距离观察点的天数(month-on-book)
** 构建流失行为的特征
 
* 第四课：GBDT 模型在流失预警模型中的应用（2 课时）
     1. GBDT 模型如何应用在金融客户流失预警模型中
     2. 如何从客户流失数据中推导 GBDT 模型的参数
     3. GBDT 模型对防范客户流失的指导意义

** GBDT(Gradient Boosting Decision Tree) 梯度提升树
  1. 特点
     - 基于简单决策树的组合模型
     - 沿着梯度下降的方向进行提升
     - 只接受数值型连续变量
  2. 优点
     - 需要做特征转化
     - 准确度高 不易过拟合模型
  3. 组合模型
     建立若干个简单的分类/回归树，组合在一起
  4. Bagging
     从同一样本、同一指标集里抽样，每次抽样都生成一棵简单树，可以并行建立
  5. Boosting (adboost, gbdt, xgboost)
     模型建立有先后顺序，后一个模型是改进对前一个模型分类错误的结果赋予更大的权重
  6. Stacking
     模型建立有先后顺序，前一个模型的输出是后一个模型的输入
     
*** GBDT 模型的原理(以分类树为例) 结构
    用𝐹 ( 𝑥 ) = Σ(k,K) 𝑓𝑘 (𝑥)来逼近 y，y 是二分类标签，K 是分类树个数

    损失函数(Loss Function)
      - 第 k 步累计函数的损失=加上第 k 棵树后的精度损失(Training Loss)+加上第 k 棵树后的 复杂度惩罚(Penalty on Complexity) • 待求变量:第 k 棵树
      - 目的: 让第 k 步累计函数的损失最小(梯度法结合泰勒展式)
      - 结束: 将第 k 棵树加到之前的模型中

    分类问题中常用的 Training Loss
      𝑙𝑦,𝑦=𝑦𝑙𝑛1+𝑒^−𝑦 + (1−𝑦)ln (1+𝑒^𝑦)
*** GBDT 模型的参数 
   1. 模型框架上的参数
    n_estimators: 分类树的个数，即 K
    learning_rate: 即每个弱学习器的权重缩减系数𝜈，也称作步长。较小的𝜈意味着需要更多 的弱学习器的迭代次数。参数 n_estimators 和 learning_rate 要一起调参。可以从一个小一点 的𝜈开始调参，默认是 1
    Subsample: (不放回)抽样率，推荐在[0.5, 0.8]之间，默认是 1.0，即不使用子采样
    init: 即初始化的时候的弱学习器，一般用在对数据有先验知识，或者之前做过一些拟合的时候
    loss: 即 GBDT 算法中的损失函数

   2. 弱分类树的参数
    max_features: 划分时考虑的最大特征数 max_depth: 决策树最大深度
    min_samples_split:内部节点再划分所需最小样本数。默认是 2.如果样本量不大，不需要管 这个值。如果样本量数量级非常大，则推荐增大这个值
    min_samples_leaf: 叶子节点最少样本数
    min_weight_fraction_leaf:叶子节点最小的样本权重。默认是 0，就是不考虑权重问题。 一般来说，如果我们有较多样本有缺失值，或者分类树样本的分布类别偏差很大，就会引 入样本权重，这时我们就要注意这个值了
    max_leaf_nodes: 最大叶子节点数，通过限制最大叶子节点数，可以防止过拟合 min_impurity_split: 节点划分最小不纯度
 
* 第五课：神经网络模型在流失预警模型中的应用（2 课时）
      1. 神经网络模型如何应用在金融客户流失预警模型中
      2. 如何从客户流失数据中推导神经网络模型的参数
      3. 神经网络模型对防范客户流失的指导意义
      4. 神经网络模型和 GBDT 模型在客户流失预警工作中的功效比较
** 神经网络(Artificial Neural Network, ANN)模型的概述
   神经网络算法的核心就是:计算、连接、评估、纠错、疯狂培训 

   ANN 的类型: 主要考虑网络连接的拓扑结构、神经元的特征、学习规则等。目前，已有近 40 种神经网络 模型，其中有反传网络、感知器、自组织映射、Hopfield 网络、波耳兹曼机、适应谐振理 论等。根据连接的拓扑结构，

   神经网络模型可以分为:
      - 前向网络
        网络中各个神经元接受前一级的输入，并输出到下一级，网络中没有反馈，可以用一个有向无环路图表示。这种网络实现信号从输入空间到输出空间的变换，它的信息处理能力来自于简单非线性函数的多次复合。网络结构简单，易于实现。反传网络是一种典型的前向网络。
      - 反馈网络
        网络内神经元间有反馈，可以用一个无向的完备图表示。这种神经网络的信息处理是状态 的变换，可以用动力学系统理论处理。系统的稳定性与联想记忆功能有密切关系。Hopfield 网络、波耳兹曼机均属于这种类型。

   损失函数
** 神经网络模型在银行客户流失预警中的作用
*** ANN 的数据预处理
    - 不能有缺失值
    - 移除常量型特征
    - 不能接受非数值形式的输入,字符型变量需要编码:
      One hot 编码
      Dummy 编码
      浓度编码
    - 变量归一化/标准化
      (𝑥−𝑚𝑖𝑛) / (max −𝑚𝑖𝑛)
* 第六课：信用卡账户违约预测模型的介绍（2 课时）
      - 信贷违约的基本概念
      - 为什么要做违约预测模型
      - 信贷违约预测模型的特性
      - 数据介绍和描述
      - 非平衡样本问题的定义和解决方法
         a.  过抽样和欠抽样
         b.  SMOTE 算法
  风险一般分为: 信用风险, 市场风险, 操作风险
    洗钱, 反洗钱等
** 信用风险
   面向个人无抵押信用贷款

   组成部分:
      - PD 违约概率
      - LGD 违约条件下的损失率
      - EAD 违约风险下的敞口暴露
      - RWA 风险权重资产
      - EL 期望损失

   坏样本的定义
      - M3&M3+逾期
        M0，M1，M2 的定义:
          + M0:最后缴款日的第二天到下一个账单日
          + M1:M0 时段的延续，即在未还款的第二个账单日到第二次账单的最后缴款日之间
          + M2:M1 的延续，即在未还款的第三个账单日到第三次账单的最后缴款日之间
      - 债务重组
      - 个人破产
      - 银行主动关户或注销
      - 其他相关违法行为
** 评分卡
   信贷场景的评分卡: 反欺诈评分卡、申请评分卡、行为评分卡、催收评分卡
   非信贷场景的评分卡: 推荐评分卡, 流失评分卡

   评分卡模型开发步骤
      I. 立项
      II. 数据准备与预处理
      III. 模型构建(训练集)
      IV. 模型评估(测试集) -- OOT(out of time, 把时间避开 --> 训练集 2016.01~2016.03, 测试集 2016.04~2016.9
      V. 验证/审计 --> 在这之前需要编写文档, 包括前边的四项都要写进去)
      VI. 模型部署
      VII. 模型监控

    评分卡开发的常用模型:
    - 逻辑回归
      优点: 简单，稳定，可解释，技术成熟，易于监测和部署 缺点:准确度不高
    - 决策树
      优点: 对数据质量要求低，易解释 缺点:准确度不高
    - 其他元模型
    - 组合模型
      优点: 准确度高，不易过拟合 缺点:不易解释;部署困难;计算量大

    模型监控的指标:
      - AR(Accuracy Ratio)
        衡量分数预测能力的指标 ，需要一个完整的表现期。取值位于-1~1 之间。(模型在 AR >=0.3 算好点) 越大越好.
        AR = (Σ_k=1~10 1/2(X(k) - X(k-1))(Y(k) + Y(k-1)) - 1/2) / (1/2(1-B_0)) ; 其中, X(k), Y(k)代表第 k 个分位点对于的累积总样本和相应的坏样本的比例. B_0 代表总的坏样本的比例.
      - KS(Kolmogorov-Smirnov)
        衡量分数区分能力的指标 越大越好.
        KS = max{Bad_k/Bad_total - Good_k/Good_total}
      - PSI(Population Stability Index)
        衡量分数稳定性的指标  (模型在 PSI <=0.25 要好点) 越小越好
        PSI = Σ_i(R_i - B_i) * ln(R_i/B_i) ; 其中, R_i 是现在样本中第 i 个组占总样本的百分比, B_i 是模型开发时第 i 个分组占总样本的百分比 
      - Kendall' Tau
        正确有效的评分卡模型中, 低分段的实际逾期率应该严格大于高分段的实际逾期率.(将分数从低到高划分为 10 组)
      - Migration Matrix
        迁移矩阵是衡量分数迁移的指标. 对相同人群, 观察在相邻两次监控日期(一周)分数的迁移变化. 迁移矩阵中 M_ij 代表上次监控日期分数在 j 组中的人群迁移到第 k 组的概率.


    开发申请评分卡的目的: 1. 风险控制; 2. 营销; 3. 资本管理.

    评分卡的特性: 1. 稳定性; 2. 区分性; 3. 预测能力; 4. 和逾期概率等价.

    贷款申请的环节 [见 ppt 20]

    贷款申请环节的数据描述 [见 ppt 23]

    申请评分卡常用的特征:
      - 个人信息 :: 学历, 性别, 收入
      - 负债信息 :: 在本霍其他金融机构负债情况
      - 消费能力 :: 商品购买记录, 出境游, 奢侈品消费
      - 历史信用记录 :: 历史逾期行为
      - 新兴数据 :: 个人社交, 网络足迹, 出行, 个人财务
** 非平衡样本问题的定义和解决方法
  非平衡样本的定义: 
    在分类问题中，每种类别的出现概率未必均衡 信用风险:正常用户远多于逾期/违约用户 流失风险: 留存客户多于流失客户

  非平衡样本的隐患: 降低对少类样本的灵敏性

  非平衡样本的解决方案:
    1. 过采样
       - 优点: 简单，对数据质量要求不高
       - 缺点: 过拟合
    2. 欠采样
       - 优点: 简单，对数据质量要求不高
       - 缺点: 丢失重要信息
    3. SMOTE(合成少数过采样技术) -- need search SMOTE 算法
       - 优点: 不易过拟合，保留信息
       - 缺点: 不能对有缺失值和类别变量做处理
       SMOTE 算法:
         1. 采样最近邻算法, 计算每个少数类样本的 K 个近邻
         2. 从 K 个近邻中随机挑选 N 个样本进行随机线性插值
         3. 构造心的少数类样本
         4. 将新样本与元数据合成, 产生新的训练集.
* 第七课：违约预测模型中的数据预处理和特征衍生（2 课时）

** 构建信用风险类型的特征
*** 时间切片
    常用时间切片: (1, 2 个)月, (1, 2 个)季度, 半年, 1 年, 1 年半, 2 年
    时间切片的选择:
      - 不能太长 :: 保证大多数样本都能覆盖到
      - 不能太短 :: 丢失信息
*** 数据清洗
    1. 对于类别型变量
       - 删除缺失率超过 50%的变量
       - 剩余变量中的缺失做为一种状态
    2. 对于连续型变量
       - 删除缺失率超过 30%的变量
       - 利用随机抽样法对剩余变量中的缺失进行补缺
       注:连续变量中的缺失也可以当成一种状态 
*** 特征的分箱
    分箱的定义
      - 将连续变量离散化
      - 将多状态的离散变量合并成少状态
    分箱的重要性
      - 稳定性:避免特征中无意义的波动对评分带来的波动
      - 健壮性:避免了极端值的影响
    分箱的优势
      - 可以将缺失作为独立的一个箱带入模型中
      - 将所有变量变换到相似的尺度上
    分箱的限制
      - 计算量大 分箱后需要编码

    分箱的方法:
      1. 有监督
         - Best-KS
         - ChiMerge(卡方分箱法)
      2. 无监督
         - 等频
         - 等距
         - 聚类
*** WOE 编码
      3. 特征的分箱
          a.  分箱的优点
          b.  Best-KS 分箱法和卡方分箱法
      4. 特征信息度的计算
 
* 第八课：违约预测模型中的数据预处理和特征衍生（续，2 课时）
      1.  分箱后如何编码
           a.  WOE 的概念、优点和计算
      2.  信用风险中的单变量分析和多变量分析
** 分箱的注意点
   1. 对于连续型变量
      - 使用 ChiMerge 进行分箱(默认分成 5 个箱)
      - 检查分箱后的 bad rate 单调性;倘若不满足，需要进行相邻两箱的合并，直到 bad rate 为止
      - 上述过程是收敛的，因为当箱数为 2 时，bad rate 自然单调
      - 分箱必须覆盖所有训练样本外可能存在的值!
   2. 对于类别型变量，
      - 当类别数较少时，原则上不需要分箱
      - 当某个或者几个类别的 bad rate 为 0 时，需要和最小的非 0bad rate 的箱进行合并
      - 当该变量可以完全区分目标变量时，需要认真检查该变量的合理性
      - 例如:“该申请者在本机构历史信用行为”把客群的好坏样本完全区分时，需要检 查该变量的合理性(有可能是事后变量)
** 特征信息度(IV)的计算和意义
   IV_i = (G_i - B_i) * log(G_i - B_i) * WOE_i; 其中, G_i, B_i 是箱 i 中好坏样本占全体好坏样本的比例, WOE 衡量两类样本分布的差异性, (G_i - B_i)衡量差异的重要性.

   特征信息度的作用 挑选变量
    - 非负指标
    - 高 IV 表示该特征和目标变量的关联度高
    - 目标变量只能是二分类
    - 过高的 IV，可能有潜在的风险
    - 特征分箱越细，IV 越高
    - 常用的阈值:
      
    <=0.02: 没有预测性，不可用;
    0.02 to 0.1: 弱预测性;
    0.1 to 0.2: 有一定的预测性 0.2 +: 高预测性
** 单变量分析
** 多变量分析
* 第九课：逻辑回归模型在违约预测模型中的应用（2 课时）
    1.  逻辑回归在违约预测模型中的作用的概述
    2.  降维的方法
          a.  主成分法
    3.  变量选择的方法
          a.  LASSO 方法
          b.  逐步回归法
          c.  随机森林法
    4.  带误判惩罚的逻辑回归模型

* 第十课：违约预测模型的评价标准（2 课时）
 
      1.  模型对违约与非违约人群的区分度
      2.  模型的准确度衡量：
           a.  尽可能抓住足够多的违约人群
           b.  尽可能不误抓非违约人群
* FQA
** 重要的分布
    [[https://zh.wikipedia.org/wiki/%E5%8D%A1%E6%96%B9%E5%88%86%E4%BD%88][卡方分布]]   [[https://en.wikipedia.org/wiki/Chi-squared_distribution][Chi-squared distribution]]

    [[https://zh.wikipedia.org/wiki/%25E5%25AD%25A6%25E7%2594%259Ft-%25E5%2588%2586%25E5%25B8%2583][t-分布]]    [[https://en.wikipedia.org/wiki/Student%2527s_t-distribution][Student's t-distribution]]

    [[https://zh.wikipedia.org/wiki/%25E5%25AD%25A6%25E7%2594%259Ft-%25E5%2588%2586%25E5%25B8%2583][F 分布]]    [[https://en.wikipedia.org/wiki/F-distribution][F-distribution]]
** 重要的一些检验方法
    卡方检验
*** 统计检验 [fn:3]
    对 LR, Wald 和 LM 检验方法的选择, 一般 W 和 LM(只需估计一个模型) 检验优于 LR 检验(需检验约束和非约束两个模型); 计算结果一般不同, 在小样本条件下: LM <= LR <= W
**** 拟合优度检验(R^2 检验)
     多元回归模型

     R^2 = S_回 / S_总 = 1 - S_残 / S_总 

     其中:
      S_总 (总变差平方和): 是各个观察值与样本均值只差的平方和, 反映了全部数据之间的差异.
      S_残 (残差平方和): 是总变差平方和中未被回归方程解释的部分.
      s_回 (回归平方和): 是总变差平方和中由回归方程解释的部分.

     0 <= R^2 <= 1, 当 R^2 越接近 1, 说明回归方程的拟合优度越高.

     为了让 R^2 能够反映被解释变量的个数, 可以定义 R^'2 = 1 - (1 - R^2 )((n - 1)/(n - k - 1), n-1 为 S_总 的自由度, n-k-1 为 S_残 的自由度.
**** 方程显著性检验(F 检验) [fn:1]
     多元回归模型

     在给定显著水平α 的情况下, 判断解释变量 y 与所有解释变量 x1, x2, ..., xk 之间的回归效果显著情况, 是否存在线性关系.

     原假设: H_0 : β1=β2=...=βk-1=0
     备泽假设: H_1 : βj 不全为 0

     原假设成立条件下, F = (explained variance) / (unexplained variance)[fn:1] ~ F(k-1, T-k), T 为样本容量, k 为非约束模型中被估参数的个数, 若 F <= F_α (k-1, T-k), 则接受 H_0; 否则, 拒绝 H_0.

***** 检验约束条件是否成立的 F 检验
      回归参数可能是一个多个线性约束条件, 判断此假设的约束条件是否成立.

      在假设约束条件成立的条件下, 统计量为
        F = ((RSS_r - RSS_u ) /m) / (RSS_u /(T-k))  [fn:1]
          RSS_r 表示施加约束条件后估计模型的残差平方和;
          RSS_u 表示未施加约束条的估计模型的残差平方和;
          m 表示约束条件个数;
          T 表示样本容量;
          k 表示非约束模型中被估参数的个数.
        若 F < F_α (m, T-k), 约束条件成立; 否则, 约束条件不成立
**** 变量显著性检验(t 检验)
     多元回归模型

     若 F 检验的结论是接受原假设, 则检验停止, 否则, 进一步作 t 检验.
     H_0 : β_j != 0, s.t. j = 1, 2, ..., k-1
     原假设成立条件下, 统计量 t ~ t(T-k), 若 |t| <= t_α (T-k), 接受 H_0 ; 否则拒绝 H_0.


     在给定显著水平α 的情况下, 判断解释变量 xj (j=1, 2, ..., k) 对被解释变-----------------量 y 的显著情况, 是否存在线性关系.

     当影响 y 的主要因素只有一个变量 x 时, t 检验可以等同于 F 检验.
**** 似然比(LR)检验 [fn:2]
     只用于对线性约束的检验

     基本思路: 如果约束条件成立, 则相应约束模型与非约束模型的极大似然函数值应该是近似相等的.

     LR = -2[logL(β1, σ1^2 ) - logL(β2, σ2^2 )    括号中是两个似然函数之比

     LR ~ χ^2 (m), 其中 m 表示约束条件个数.
     判别规则是: 若 LR<χ^2 α(m), 则接受零假设, 约束条件成立; 否则, 约束条件不成立.

**** Wald 统计量
     检验回归参数线性约束与非线性约束成立
     优点: 只需估计无约束模型, 当约束模型的估计很困难时, 此方法尤其适用.

     原理: 测量无约束估计量与约束估计量之间的距离.
**** 拉格朗日(LM)统计量
     检验回归参数线性约束与非线性约束成立
**** JB 正态性检验(检验正态分布)
     偏度: 三次方
     峰度(峤度): 四次方

     JB = ((T-n)/6)[S^2 + (1/4)(k-3)^2 ] ~ X^2 (2); 其中 T 表示观测值个数, S 表示偏度, K 表示峤度

     若 JB<X^2 α(2), 该分布为正态分布, 否则不是正态分布.
**** 赤池准则(AIC), 贝叶斯信息准则(BIC), 汉南-奎因准则(HQ)
     检验模型最优滞后期

     赤池信息准则: AIC = -2logL + 2k, 其中 logL 表示对数似然函数极大值, T 是样本容量, k 表示模型中变量的最大滞后期.

     施瓦茨准则(SC), 又称贝叶斯信息准则(BIC): SC = BIC = -2logL + klogT, 其中 logL, T, K 定义与 AIC 公式中类似.

     汉南-奎因准则(HQ): HQ = -2(logL)/T + 2k(ln(lnT))/T, 其中 logL, T, K 定义与 AIC 公式中类似.
**** 格兰杰(Granger)因果性检验
     检验变量间因果关系

     如果由 yt 和 xt 滞后值所决定的 yt 的条件分布和仅由 yt 滞后值所决定的条件分布相同, 则成 x(t-1)对 yt 存在格兰杰非因果性;
       即: f(yt|y(t-1), ..., x(t-1), ...) = f(yt|y(t-1), ...)
     可以被解释为模型以 yt 为变量的方程中是否可以把 xt 的全部之后变量剔除掉而完成.
**** Chow 突变点检验和邹稳定性检验
      检验模型是否存在结构变化
***** 邹突变点检验

      同一问题, 在不同时段的两个子样本, 需要考察两个不同时段的回归系数是否相同, 此检验也适用于两个截面样本的情形.
      需要求各残差和自由度

      原假设: H_0 : α_j = Β_j, j = 1, 2, ..., k-1.
      备择假设: H_1 : α_j, Β_j 不全对应相等.

      F ~ F(k, t-2k)
      检验规则:
        若 F>F_α(k, T-2k), 拒绝 H_0 (回归系数有显著变化), 否则接受 H_0.
***** 回归系数稳定性的邹(chow)检验
      在样本 T 基础上求出回归模型系数的估计值后, 再增加 n 个观测值, 从而考察原参数估计值的稳定性

      原假设: H_0 : α_j = Β_j, j = 1, 2, ..., k-1.
      备择假设: H_1 : α_j, Β_j 不全对应相等.

      F ~ F(n, T-k), 若 F < F_α(n, T-k), 则接受 H_0 (无显著变化); 否则拒绝 H_0.
**** 递归分析
     只适用于最小二乘估计的模型.

     采取逐次增加一期观测值的方法进行回归分析. 需计算递归残差和递归参数等.

     累计递归残差检验(CUSUM Test) : 统计量 (W_t) ; 如果回归参数稳定, 则, E(W_t) = 0, 否则, 将离开零均值线, 如果 W_t 值到了 5%显著性曲线以外, 预示着模型回归参数不稳定.
     累计递归残差平方检验(CUSUM of Squares Test)
**** 模型诊断与 EViews 操作
     在 EViews 中, 模型诊断和检验功能可以分为三大类.
* Footnotes

[fn:3] [[http://doc.mbalib.com/view/e2a3f64315dcbc693d1982de0d79799e.html][模型检验的常用统计量]]

[fn:2] [[https://en.wikipedia.org/wiki/Likelihood-ratio_test][Likelihood-ratio test wiki]]

[fn:1] [[https://en.wikipedia.org/wiki/F-test][F-test wiki]]  [Multiple-comparison ANOVA problems]  [Regression problems]
