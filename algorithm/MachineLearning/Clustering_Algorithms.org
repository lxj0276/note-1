* link
[[http://blog.chinaunix.net/uid-10289334-id-3758310.html][聚类算法总结]]
* 聚类算法
聚类分析在电子商务、图像处理、模式识别、文本学习、数据库等领域有广泛的应用背景。聚类与分类的根本不同在于: 分类问题中我们知道训练集的分类属性, 而聚类问题则需要我们从数据集中找这个分类属性。所谓聚类, 就是对数据集中的数据应用某种方法进行分组, 使得每组内部的数据尽可能相似而不同组之间的数据尽可能不同, 从而发现数据集内在的结构。其中数据集可以是结构数据、半结构数据、非结构化数据、多媒体数据、有序数据集等, 对于不同的数据集要采用不同的方法。
* 数据挖掘中常用聚类算法的比较
　为了找到一个效率高且通用性强的聚类算法, 人们从不同角度提出了数十种聚类算法。在数据挖掘中, 常用的有: K2p rototypes 方法, CLARAN S 算法, BIRCH 算法, CU RE 算法, DBSCAN 算法, W aveCluster 算法, CL IQU E 算法等[1, 5, 6, 7 ]。
** K-prototypes 算法
该算法综合了 K-means 方法和 K-modes 方法的特点, 能够处理数值类型和符号类型的数据。
数值类型用欧式距离测量相似性, 符号类型用海明距离测量相似性, 将两部分综合起来构造评价函
数, 是一种有约束优化的聚类方法。
** CLARANS 算法
该算法将采样技术和 PAM 相结合。它首先随机选择一个点作为当前点, 然后随机检查它周围
不超过参数 M axneighbor 的一些邻居, 假如找到一个比它更好的邻居 (即有更小的平方误差值),
则把它移入到该邻接点, 否则把该点作为局部最小量。如果找到一个局部最优, 它又随机选择一个
结点开始寻找新的局部最优, 直到满足用户的要求为止。此方法计算复杂度 O (n2), 对噪声数据
不敏感, 但对数据输入顺序敏感, 只能聚类凸状或球型边界。
** BIRCH 算法
该算法是一种综合优化的多阶段聚类技术, 它的核心是采用了一个三元组的聚类特征树 (CF
树) 汇总了一个簇的有关信息, 从而使一个簇的表示可以用对应的聚类特征, 而不必用具体的一组
点表示, 通过构造分支因子 B 和簇直径阈值 T 来进行增量和动态聚类。该方法通过一次扫描就可
以进行较好聚类, 比较适合于大型数据集。但它只适合于类的分布呈凸状或球状情况, 需要提供正
确的聚类数和对簇直径 T 的仔细选择, 不适于高维数据。
** CURE 算法
该算法采用了基于质心和基于代表对象方法之间的中间策略。它不用单个质心或对象来代表
一个簇, 而选择数据空间中固定数目的具有代表性的点, 并将这些点乘以一个适当的收缩因子, 使
它们更靠近簇的中心。选择多个代表使得该算法可以适应非球状的几何形状, 簇的收缩或凝聚可以
有助于控制噪声的影响。同时该方法采用了随机抽样与分割相结合来提高效率, 对大型数据库有良
好的伸缩性。
** DBSCAN 算法
该算法是在数据集上定义一种密度可达等价关系, 对应的划分就是聚类。密度可达关系定义
为: 如果一个对象的 Ε- 领域至少包含了最小数目的 M inp ts 个对象, 该对象为核心对象; 如果 p 是
在核心对象 q 的 Ε- 领域, 则称对象 p 为对象 q 的直接密度可达; 如果存在对象链 p1, p2, 11, pn,
p1= q, pn=p, 对 pi∈D (对象集), pi+ 1 是从 pi 关于 Ε和 M inp ts 的直接密度可达, 则对象 p, q 是
关于 Ε和 M inp ts 密度可达的。此方法是通过不断执行区域查询来实现聚类。时间复杂度为 O
(nlogn), 对 Ε和 M inp ts 相对敏感, 两参数难以确定。
** WaveCluster 算法
该算法是一种基于多分辨率变换的聚类方法, 它首先在数据空间上强加一个多维网格结构来
汇总数据, 然后采用一种小波变换来变换原特征空间, 在变换后的空间找到聚类区域。由于小波变
换的特性使该算法具有很多优点: 计算复杂度为 O (n), 发现任意形状的簇, 成功处理孤立点, 对
输入顺序不敏感, 领域独立, 可以处理多达 20 维的数据。
　　表 2　数据挖掘中常用算法比较
类型 可伸
缩性
适合的数
据类型
发现的聚
类形状
领域知识
依赖性
对噪声的
敏感性
对输入顺
序敏感性
处理高维数
据的能力
K2p rototypes 优化 一般 数值, 符号 凸状, 球形 大 敏感 一般 较低
CLARAN S 优化 较低 数值 凸状, 球形 大 不敏感 敏感 较低
B IRCH 优化 较高 数值 凸状, 球形 大 不敏感 一般 较低
CU RE 优化 较高 数值 任意 大 不敏感 一般 一般
DBSCAN 关系 一般 数值 任意 低 一般 一般 一般
W aveCluster 变换 高 数值 任意 低 不敏感 不敏感 高
CL IQU E 变换 高 数值 任意 低 一般 不敏感 高
**  CLIQUE 算法
该算法是一种基于密度 (关系) 和网格 (变换) 的聚类方法, 它利用了关联规则挖掘中的先验
性质: 如果一个 k 维单元是密集的, 那么它的 k- 1 维空间上的投影也是密集的。中心思想是: 给
定一个多维数据点的大集合, 数据点在数据空间中通常不是均衡分布的。该算法区分空间中稀疏的
和“拥济的”区域 (单元), 发现数据集合的全局分布模式, 如果一个单元中包含的数据点数超过
了某个输入参数, 则该单元是密集的。在 CL IQU E 算法中, 簇定义为相连的密集单元的最大集合。
该方法对数据输入顺序不敏感, 对数据高维有良好的伸缩性, 但需要用户输入数据聚类空间等间隔
距离和密度阈值参数, 由于方法简化, 聚类结果的精确可能降低。
基于上述分析, 数据挖掘中常用聚类算法比较结果如表 2 所示
　　由于每种算法都有其优点和不同的应用领域, 在数据挖掘中应根据实际需要选择适当的聚类
算法。

* 用于数据挖掘的聚类算法
** 分层聚类算法
分层聚类通过建立系统树图进行分类。
分层聚类分为两种：凝聚算法（自底而上）分裂算法（自顶向下），两种算法都需要预先设定一个终止条件（如类数目）。
凝聚算法：先将每个样本看成一个类，然后根据条件将其与最临近样本融合为另一个类，如此迭代。
分裂算法：先将所有样本看成一个类，然后进行迭代分裂。
分裂聚类算法使用于文档数据库挖掘和信息修复等应用，其中最常用的是 PDDP(Principal Direction Divisive Partitioning)算法，它采用了奇异值分解（SVD）进行分裂聚类。

分层算法的优点：灵活性，可以在不同层次分类;可以处理任何类型的相似性;可以处理任何属性的数据。
缺点：算法终止条件不明确;处理过程中没有向上层反馈信息，没有优化过程。

典型分层聚类算法：N*N 连接矩阵为处理对象，矩阵元素是样本间距离。
通常采用两种方法将该矩阵稀疏化：
+ 设立门限，将小于门限值的元素置零;
+ 矩阵中只保留各样本与若干最临近样本间距离。
连接矩阵不能解决具有不规则形状的数据库聚类问题。

CURE(Clustering Using Representatives)算法和 CHAMELEON 算法较好的解决了不规则形状数据库聚类问题。
CURE 算法用几个具有代表性的分散点代表各类，通过选取适当的点代表任意形状的类，在迭代过程中收缩代表点，使其向几何质心靠拢，以进一步减少外来点的干扰。该算法主要用于低维空间数字属性聚类。
CHAMELEON 算法利用动态模型进行凝聚，以连接图 G 取代稀疏连接矩阵，仅保留每个样本与最临近的 K 样本之间的距离，其余样本间距离被删除。

传统的分层聚类算法在凝聚或分裂后没有优化过程，不能随处理时间的增加改善聚类效果。在字符属性聚类中最常用的 COBWEB 算法，则克服了这个缺点，它采用增量学习方法建立动态系统树图，每次处理一个数据，是基于模型的无督促学习过程。
** 分割聚类算法
** 基于密度的聚类算法
** 基于栅格的聚类算法
** 对字符属性的聚类
** 高维数据聚类
** 神经网络聚类
