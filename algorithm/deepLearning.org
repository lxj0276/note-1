github: wiibrew

* 总体介绍
1. 特征提取： 查询人工设计模式：Hog..
  目标探测

2. 理论:CNN,RNN,ReLU(可以让网络撘的很深)

3. 图像处理基础知识， 卷积核

4. QDN(增强学习）

5. word2vec
** 人工神经网络（artificial neural network，缩写 ANN），简称神经网络（neural network，缩写 NN）或类神经网络
   典型的神经网络具有以下三个部分：
   1. 结构 （Architecture） 结构指定了网络中的变量和它们的拓扑关系。例如，神经网络中的变量可以是神经元连接的权重（weights）和神经元的激励值（activities of the neurons）。
   2. 激励函数（Activity Rule） 大部分神经网络模型具有一个短时间尺度的动力学规则，来定义神经元如何根据其他神经元的活动来改变自己的激励值。一般激励函数依赖于网络中的权重（即该网络的参数）。
   3. 学习规则（Learning Rule）学习规则指定了网络中的权重如何随着时间推进而调整。这一般被看做是一种长时间尺度的动力学规则。一般情况下，学习规则依赖于神经元的激励值。它也可能依赖于监督者提供的目标值和当前权重的值。
* 传统神经网络
  1. GAN

  2. 非线性激励函数的要求(1. ...  2.反向梯度的损失)
     非线性激励函数的优点，缺点

  3. back propa.., ensemble, vgg,
     dropout with polling, slam
* 卷积神级网络-目标探测
期待目标:
1. 了解目标探测的处理流程,明白同目标识别的区别联系
2. 了解传统目标探测处理方法
3. 清楚 RCNN 系列方法的进阶,每次提升针对问题以及解决方法
4. YoLo 系列方法的特点,同 RCNN 系列对比
5. 会应用已有目标探测模型定位,知道如何训 练特殊目标探测模型
** 目标探测介绍
   单个目标
   多个目标

   直接思路:
     1. 回归问题:　利用神经网络进行目标识别, 同样的目标变为坐标值
     2. 局部识别问题: 在很多位置尝试识别，　能够完成识别的地方就是目标位置.　proposal (候选位置）的产生.
        不同 scala 的 sliding windows? 更有效的方法是什么？　遍历所有的位置（计算量大,低效）,直接计算候选区域.
   
     转化为回归,分类问题. 分类思想目标探测: 候选区域的产生.
** 传统方法-DPM(Deformable Parts Model)
  优点:
  1. 方法直观简单
  2. 运算速度快
  3. 适应运动物体变形
  4. 至 2012 年,最好方法
  
  缺点:
  1. 性能一般
  2. 激励特征人为设计,工作量大
  3. 大幅度旋转无法适应,稳定性差

   基本思想: 提取图像特征,制作出激励模版,在原始图像滑动计算,得到激励效果图,根据激励分布确定目标位置.

   拓展: 目标可能会形变,各个部分单独考虑
   1. 产生多个模版,整体模版以及不同局部模版
   2. 不同模版同输入图片“卷积”产生特征图
   3. 特征图组合形成融合特征
   4. 对融合特征进行传统分类, 回归,得到目标位置
** 神经网络分类:RCNN(region cnn) 系列方法
*** R-CNN
  优点:
    1. CNN 用于目标探测,利用了 CNN 高效识别能力, 大大提高性能
    2. 摆脱人为设计物品模版, 方法具有通用性
    3. 分类+回归,有了找到精确位置的可能互联网新技术在线教育领航者
  缺陷: (解决:  Fast R-CNN - 1. 共享卷积计算 2. 完整训练(end-to-end) 3. 多目标一起学习)
    1. 为了检测一个目标,所有候选区域计算,大量卷积运算,非常慢
    2. SVM 训练与 CNN 断裂, 有效信息不能用于优化模型, not end-to-end。
    3. 每一类单独训练,异常繁琐

   神经网络分类思想: 对多个位置,不同尺寸,用卷积神经网络判断区域内图片是不是某物
   候选位置(proposal)提出方法:EdgeBox

   1. 分类器的训练 - 直接用 ImageNet 模型
   2. Fine-tune 分类模型, 对原始分类模型结构更改, 选择 20 类进行探测, 分为 20 类+其他,总共 21 类.
   3. 图片计算候选区域;候选区域切分图片,变成输入大小; 提取相应高级特征;存储特征(很大容量)
   4. 单独目标探测器训练(一个类一个类考虑)
      每一类单独训练
      每一类训练数据平衡
      每一类 binary 分类
   5. 单独目标回归器训练-基于候选区域微调
      每一类单独训练
      每一类训练数据平衡
      每一类 BBOX 回归

   测试过程:
    1. 候选区域
    2. 特征计算
    3. 分类, 回归
    4. 后续处理

   评估方法:
   mAP: mean aerage precision. 平均精度.
   IoU = (Area of Overlap)/(Area of Union)

   常用数据集:
|                               | PASCAL VOC(2010) | ImageNet Deection(ILSVRC 2014 | MS-COCO(2014) |
|-------------------------------+------------------+-------------------------------+---------------|
| Number of classes             |               20 |                           200 |            80 |
| Number of images(train + val) |             ~20K |                         ~470K |         ~120K |
| Mean objects per image        |              2.4 |                           1.1 |           7.2 |

*** Fast R-CNN
    直接联合学习(一个网络, 四个损失函数):
    1. Anchor 是不是目标
    2. Anchor 回归候选区域回归
    3. Fast R-CNN 分类
    4. Fast R-CNN 基于候选位置回归

    神经网络特征增加一组输出
    RPN(Region Proposal Network) 候选区域网络
    1. 直接产生候选区域,无需无需额外生成
    2. 直接用于后续特征图切割
**** 共享卷积计算
     1. 卷积计算保持空间位置
     2. 共同区域的卷积计算只需进行一次
     3. 切割候选区 + 提取特征图 = 计算完整特征图 + 切割对应候选区
**** 特征一致化(max pooling)
**** 位置 + 类别 联合学习(类别分数判定 + 相对位置回归

** 神经网络回归:YoLo,SSD(The Single Shot Detector) 系列方法
   YoLo 训练
    图片分成 7x7 网格
    每个网格生成:
    1. b 个 Bbox 4 坐标+1 信心
    2. N 个类别分数 ( 注意对比 Anchor )
    总共回归目标:7x7x(5b+N)
    候选区域个数(b=2)98 个,《Faster R-CNN

    SSD: 中间层特征参与位置,种类计算
** 实例: 目标探测模型训练和部署

** FQA
*** hog 特征, 方向梯度直方图（Histogram of Oriented Gradient, HOG）
*** fine-tune
*** bbox(bounding box) 回归
*** YoLo
* 递归神经网络(RNN)
** RNN
提纲:
  1. 递归神经网络 RNN 原理
  2. 升级版 RNN:LSTM
  3. 语言处理特征提取:Word2Vec
  4. 实例:LSTM 用于语言处理

期待目标:
  1. 理解从传统神经网络到递归神经网络 RNN 的转化
  2. RNN 特点,缺陷,LSTM 的设计
  3. 理解 word2vec 设计,特点,明白如何
  4. 了解 LSTM 与 word2vec 结合用于语言相关应用

传统神经网络:
  - 输入, 输出, 隐含层
  - 如果 x 为序列,输出影响?
  - 是否有记忆能力?

递归神经网络:
  - 中间层激励保存
  - 下一刻重新输入
  - 记忆功能

正向计算-损失函数; 反向计算-梯度下降求导数

反向计算(Backpropagation Through Time, BPTT):
  链式法则, 梯度前向传导
** LSTM
   RNN 局限: 距离太远难以产生关联 --> 设计 Gate, 保存重要记忆.
** LSTM-GRU(Gated Recurrent Unit) 
http://wiseodd.github.io/techblog/2016/08/12/lstm-backprop/
** word2vec
* 卷积网络+递归网络
提纲:
  1. CNN+RNN
  2. 图片标注
  3. 视频行为识别
  4. 图片/视频问答
  5. 实例学习 Image Caption 图片自动标注

期待目标:
  1. 了解传统神经网络空间时间扩展概念
  2. CNN,RNN 特征提取方面异同,结合的特点,在图片标注/视频分类/图片问答 应用中的作用
  3. 明白图片标注的训练流程,能够运用现有 package 完成训练和测试
** CNN + RNN
*** cnn, rnn 的异同
    cnn - 输入主要是二维分布(比如图片), 设计二维的卷积核, 每个位置会产生一个激励. 输入是二维的, 时间上没有考虑. 
    rnn - 中间计算结果进行保持, 下次训练的时候中间量会参与计算. 输入是一维的, 时间上有一个考虑.

**** 相同点:
      1. 传统神经网络的扩展
      2. 前向计算产生结果, 反向计算模型更新(梯度下降法, 一个初始参数, 根据计算结果跟标准值比较得到一个 loss, 根据 loss 对每一个参数求偏导, 然后根据 learning rate, 更新模型参数.
      3. 每层神经网络横向可以多个神经元共存, 纵向可以有多层神经网络连接
      
**** 不同点:
      1. cnn 空间扩展, 神经元与与特征卷积;RNN 时间扩展,神经元与多个时间输出计算
      2. RNN 可以用于描述时间上连续状态的输出, 有记忆功能,CNN 用于静态输出
      3. CNN 高级 100+深度,RNN 深度有限(激励层用的 sigmod 的, 层数多了可能衰减比较多, 目前五层以上的很少)
*** 组合意义
    1. 大量信息同时具有时间空间特性: 视频, 图片结合等
    2. 带有图像的对话, 文本表达更具体
    3. 视频相对图片描述的内容更完整
*** 组合方式及实现
**** 组合方式
    1. cnn 特征提取,用于 RNN 语句生成 -> 图片标注
    2. RNN 特征提取用于 CNN 内容分类 -> 视频分类
    3. CNN 特征提取用于对话问答 -> 图片问答
**** 实现
    1. 特征提取:LSTM 输出,FC 层输出
    2. 特征合并:Concatenate 层;Attention 相乘
    3. 结果输出:连续语句输出 LSTM,组合分类回归 DNN
** 图片标注
   问题描述: 拥有大量图片及标注信息, 能否通过学习建立一个能够自动图片标注的模型.

   基本思路:
     1. 目标是产生标注的语句,是一个语句生成的任务,LSTM?
     2. 描述的对象大量图像信息,图像信息表达, CNN?
     3. CNN 网络中全连接层特征描述图片,特征与 LSTM 输入结合?
** 视频行为识别
** 图片/视频问答
** 实例学习 Image Caption 图片自动标注
** FQA
   1. 迁移学习
   2. dense cap
   3. gnn(生成图片),  生成视频
